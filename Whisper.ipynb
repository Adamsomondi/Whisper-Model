{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOFy3YeIMRJR9WryxxcgI9u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Local Video Text Extraction from Google Drive in Google Colab\n","\n","# Step 1: Install required packages\n","!pip install openai-whisper torch torchaudio #openaiwhisper transcribes audio to text,torch is the engine,torchaudio processing, and transforming audio.\n","!pip install moviepy  # For video processing to audio if needed.\n","\n","# Step 2: Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Step 3: Import libraries\n","import whisper        # Load the Whisper model.\n","import torch          # Backend engine for AI processing.\n","import re             # For cleaning text (regex operations).\n","import os             # File management (list folders, move files).\n","from pathlib import Path  # Easier handling of file paths.\n","import json           # Saving and loading transcripts/metadata.\n","from datetime import datetime  # Timestamps for files or logs.\n","\n","# Step 4: List files in your Google Drive (optional - to find your video)\n","def list_drive_files(folder_path=\"/content/drive/MyDrive\"):\n","    \"\"\"List files in Google Drive folder\"\"\"\n","\n","    print(\"Files in your Google Drive:\")\n","    for root, dirs, files in os.walk(folder_path):\n","        level = root.replace(folder_path, '').count(os.sep)\n","        indent = ' ' * 2 * level\n","        print(f\"{indent}{os.path.basename(root)}/\")\n","        subindent = ' ' * 2 * (level + 1)\n","        for file in files:\n","            if file.endswith(('.mp4', '.avi', '.mkv', '.mov', '.wmv', '.flv', '.webm', '.m4v')):\n","                print(f\"{subindent}📹 {file}\")\n","            elif file.endswith(('.mp3', '.wav', '.m4a', '.flac', '.aac')):\n","                print(f\"{subindent}🎵 {file}\")\n","\n","# Step 5: Transcribe video/audio file\n","def transcribe_local_file(file_path, model_size=\"base\", language=None):\n","    \"\"\"Transcribe local video or audio file using Whisper\"\"\"\n","\n","    # Check if file exists\n","    if not os.path.exists(file_path):\n","        print(f\"Error: File not found at {file_path}\")\n","        return None\n","\n","    print(f\"Loading Whisper model: {model_size}\")\n","    model = whisper.load_model(model_size) #It Downloads the Model Automatically\n","\n","    print(f\"Transcribing: {os.path.basename(file_path)}\")\n","\n","    # Transcribe with options\n","    options = {\n","        \"fp16\": torch.cuda.is_available(),  # Use fp16 if GPU available\n","        \"language\": language,  # Auto-detect if None\n","        \"task\": \"transcribe\"\n","    }\n","\n","    result = model.transcribe(file_path, **options)\n","\n","    return result\n","\n","# Step 6: Search for keywords with timestamps\n","def search_keywords_with_context(result, keywords, context_seconds=10):\n","    \"\"\"Search for keywords in transcript with timestamp context\"\"\"\n","\n","    matches = []\n","\n","    for segment in result['segments']:\n","        text = segment['text']\n","        start_time = segment['start']\n","        end_time = segment['end']\n","\n","        for keyword in keywords:\n","            if keyword.lower() in text.lower():\n","                # Format timestamp\n","                start_min = int(start_time // 60)\n","                start_sec = int(start_time % 60)\n","\n","                matches.append({\n","                    'keyword': keyword,\n","                    'text': text.strip(),\n","                    'start_time': start_time,\n","                    'end_time': end_time,\n","                    'formatted_time': f\"{start_min:02d}:{start_sec:02d}\",\n","                    'confidence': segment.get('confidence', 0)\n","                })\n","\n","    return matches\n","\n","# Step 7: Advanced phrase search\n","def search_phrases_in_segments(result, phrases):\n","    \"\"\"Search for exact phrases across segments\"\"\"\n","\n","    matches = []\n","    full_text = result['text']\n","\n","    for phrase in phrases:\n","        pattern = re.compile(re.escape(phrase), re.IGNORECASE)\n","\n","        for match in pattern.finditer(full_text):\n","            # Find which segment this belongs to\n","            char_position = match.start()\n","\n","            # Calculate approximate timestamp based on character position\n","            char_per_second = len(full_text) / result['segments'][-1]['end'] if result['segments'] else 1\n","            approx_time = char_position / char_per_second\n","\n","            # Get context\n","            start_context = max(0, match.start() - 100)\n","            end_context = min(len(full_text), match.end() + 100)\n","            context = full_text[start_context:end_context]\n","\n","            matches.append({\n","                'phrase': phrase,\n","                'context': context,\n","                'approximate_time': approx_time,\n","                'formatted_time': f\"{int(approx_time//60):02d}:{int(approx_time%60):02d}\",\n","                'exact_match': match.group()\n","            })\n","\n","    return matches\n","\n","# Step 8: Extract and analyze topics\n","def extract_topics_by_length(result, min_words=10, max_words=50):\n","    \"\"\"Extract segments of specific length that might contain topics\"\"\"\n","\n","    topics = []\n","\n","    for segment in result['segments']:\n","        words = segment['text'].split()\n","        word_count = len(words)\n","\n","        if min_words <= word_count <= max_words:\n","            topics.append({\n","                'text': segment['text'].strip(),\n","                'word_count': word_count,\n","                'start_time': segment['start'],\n","                'end_time': segment['end'],\n","                'duration': segment['end'] - segment['start'],\n","                'formatted_time': f\"{int(segment['start']//60):02d}:{int(segment['start']%60):02d}\"\n","            })\n","\n","    return topics\n","\n","# Step 9: Save results to files\n","def save_results(results, base_filename=\"video_analysis\"):\n","    \"\"\"Save analysis results to files\"\"\"\n","\n","    # Save full transcript\n","    with open(f'/content/drive/MyDrive/{base_filename}_transcript.txt', 'w', encoding='utf-8') as f:\n","        f.write(results['full_transcript'])\n","\n","    # Save keyword matches\n","    with open(f'/content/drive/MyDrive/{base_filename}_keywords.json', 'w', encoding='utf-8') as f:\n","        json.dump(results['keyword_matches'], f, indent=2, ensure_ascii=False)\n","\n","    # Save analysis summary\n","    summary = {\n","        'video_file': results['video_file'],\n","        'analysis_date': datetime.now().isoformat(),\n","        'transcript_length': len(results['full_transcript']),\n","        'total_segments': len(results['segments']),\n","        'keyword_matches_count': len(results['keyword_matches']),\n","        'topics_found': len(results.get('topics', []))\n","    }\n","\n","    with open(f'/content/drive/MyDrive/{base_filename}_summary.json', 'w', encoding='utf-8') as f:\n","        json.dump(summary, f, indent=2, ensure_ascii=False)\n","\n","    print(f\"Results saved to Google Drive:\")\n","    print(f\"- {base_filename}_transcript.txt\")\n","    print(f\"- {base_filename}_keywords.json\")\n","    print(f\"- {base_filename}_summary.json\")\n","\n","# Step 10: Main processing function\n","def process_local_video(video_path, keywords, phrases=None, model_size=\"base\"):\n","    \"\"\"Complete pipeline for local video processing\"\"\"\n","\n","    print(f\"Processing local video: {video_path}\")\n","\n","    # Transcribe\n","    result = transcribe_local_file(video_path, model_size)\n","\n","    if not result:\n","        return None\n","\n","    # Search keywords\n","    keyword_matches = search_keywords_with_context(result, keywords)\n","\n","    # Search phrases if provided\n","    phrase_matches = []\n","    if phrases:\n","        phrase_matches = search_phrases_in_segments(result, phrases)\n","\n","    # Extract topics\n","    topics = extract_topics_by_length(result)\n","\n","    # Compile results\n","    analysis_results = {\n","        'video_file': os.path.basename(video_path),\n","        'full_transcript': result['text'],\n","        'segments': result['segments'],\n","        'keyword_matches': keyword_matches,\n","        'phrase_matches': phrase_matches,\n","        'topics': topics,\n","        'detected_language': result.get('language', 'unknown')\n","    }\n","\n","    return analysis_results\n","\n","# Step 11: Usage example\n","if __name__ == \"__main__\":\n","    # First, list files to find your video\n","    print(\"Scanning Google Drive for video files...\")\n","    list_drive_files()\n","\n","    # Set your video path - UPDATE THIS PATH\n","    video_path = \"/content/drive/MyDrive/videoplayback.mp4\"  # Change this to your actual video path\n","\n","    # Define keywords to search for\n","    keywords_to_search = [\n","\"real estate\",\n","\"property investment\",\n","\"affordable housing\",\n","\"commercial property\",\n","\"rental yield\",\n","\"capital gains\",\n","\"title deed\",\n","\"leasehold\",\n","\"freehold\",\n","\"REIT\",\n","\"project finance\",\n","\"joint venture\",\n","\"real estate law\",\n","\"zoning regulations\",\n","\"building permit\"\n","    ]\n","\n","    # Define phrases to search for (optional)\n","    phrases_to_search = [\n","    \"real estate investment\",\n","    \"affordable housing project\",\n","    \"commercial property market\",\n","    \"rental income strategy\",\n","    \"property title deed\",\n","    \"leasehold land rights\",\n","    \"freehold property ownership\",\n","    \"joint venture agreement\",\n","    \"real estate financing\",\n","    \"public private partnership\",\n","    \"zoning and planning laws\",\n","    \"building code compliance\",\n","    \"capital gains tax\",\n","    \"real estate regulatory framework\",\n","    \"infrastructure-led development\"\n","    ]\n","\n","    # Process the video\n","    print(f\"\\nProcessing video: {video_path}\")\n","    results = process_local_video(\n","        video_path,\n","        keywords_to_search,\n","        phrases_to_search,\n","        model_size=\"base\"  # Options: tiny, base, small, medium, large\n","    )\n","\n","    if results:\n","        print(f\"\\n✅ Analysis Complete!\")\n","        print(f\"Video: {results['video_file']}\")\n","        print(f\"Language detected: {results['detected_language']}\")\n","        print(f\"Transcript length: {len(results['full_transcript'])} characters\")\n","        print(f\"Total segments: {len(results['segments'])}\")\n","\n","        # Display keyword matches\n","        print(f\"\\n🔍 Found {len(results['keyword_matches'])} keyword matches:\")\n","        for match in results['keyword_matches'][:10]:  # Show first 10\n","            print(f\"  ⏰ {match['formatted_time']} - '{match['keyword']}'\")\n","            print(f\"     Context: {match['text'][:100]}...\")\n","\n","        # Display phrase matches\n","        if results['phrase_matches']:\n","            print(f\"\\n📝 Found {len(results['phrase_matches'])} phrase matches:\")\n","            for match in results['phrase_matches'][:5]:  # Show first 5\n","                print(f\"  ⏰ {match['formatted_time']} - '{match['phrase']}'\")\n","\n","        # Display interesting topics\n","        print(f\"\\n💡 Found {len(results['topics'])} potential topics:\")\n","        for topic in results['topics'][:5]:  # Show first 5\n","            print(f\"  ⏰ {topic['formatted_time']} - {topic['text'][:80]}...\")\n","\n","        # Save results\n","        save_results(results, \"video_analysis\")\n","\n","    else:\n","        print(\"❌ Failed to process video\")\n","\n","# Step 12: Helper functions for specific searches\n","def search_technical_terms(result):\n","    \"\"\"Search for common technical terms\"\"\"\n","\n","    technical_terms = [\n","    \"title deed\",\n","    \"lease agreement\",\n","    \"freehold\",\n","    \"leasehold\",\n","    \"zoning\",\n","    \"easement\",\n","    \"land use\",\n","    \"conveyancing\",\n","    \"due diligence\",\n","    \"real estate appraisal\",\n","    \"escrow\",\n","    \"capital gains\",\n","    \"mortgage\",\n","    \"stamp duty\",\n","    \"building permit\",\n","    \"property tax\",\n","    \"joint venture\",\n","    \"valuation\",\n","    \"real estate financing\"\n","    ]\n","\n","    return search_keywords_with_context(result, technical_terms)\n","\n","def search_business_terms(result):\n","    \"\"\"Search for business-related terms\"\"\"\n","\n","    business_terms = [\n","        \"revenue\", \"profit\", \"loss\", \"investment\", \"ROI\", \"KPI\", \"metrics\",\n","        \"strategy\", \"market\", \"customer\", \"client\", \"sales\", \"marketing\",\n","        \"budget\", \"cost\", \"price\", \"value\", \"growth\", \"competition\"\n","    ]\n","\n","    return search_keywords_with_context(result, business_terms)\n","\n","# Quick setup instructions:\n","print(\"\"\"\n","🚀 QUICK SETUP INSTRUCTIONS:\n","\n","1. Upload your video to Google Drive\n","2. Run the drive.mount() cell to connect to Google Drive\n","3. Update the video_path variable with your actual video path\n","4. Customize keywords_to_search with your specific terms\n","5. Run the main processing function\n","6. Check the results and saved files in your Google Drive\n","\n","📝 Supported formats: MP4, AVI, MKV, MOV, WMV, FLV, WebM, M4V, MP3, WAV, M4A, FLAC, AAC\n","\n","⚡ Model options (speed vs accuracy):\n","- tiny: Fastest, least accurate\n","- base: Good balance (recommended)\n","- small: Better accuracy\n","- medium: High accuracy, slower\n","- large: Best accuracy, slowest\n","\"\"\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U5SY_eH9wKPR","executionInfo":{"status":"ok","timestamp":1756907724354,"user_tz":-180,"elapsed":117477,"user":{"displayName":"Adams nogo","userId":"04938037951963737511"}},"outputId":"5ae0437a-2bbe-43ef-98ee-978b955da347"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting openai-whisper\n","  Downloading openai_whisper-20250625.tar.gz (803 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/803.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m706.6/803.2 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.2/803.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.7.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (2.0.2)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.11.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (4.67.1)\n","Requirement already satisfied: triton>=2 in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (3.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba->openai-whisper) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken->openai-whisper) (2.32.4)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2025.8.3)\n","Building wheels for collected packages: openai-whisper\n","  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for openai-whisper: filename=openai_whisper-20250625-py3-none-any.whl size=803979 sha256=50a6d7f8441f462d5aaab63481716344ac0617a3ef3b51e2441d74e52f2338ef\n","  Stored in directory: /root/.cache/pip/wheels/61/d2/20/09ec9bef734d126cba375b15898010b6cc28578d8afdde5869\n","Successfully built openai-whisper\n","Installing collected packages: openai-whisper\n","Successfully installed openai-whisper-20250625\n","Requirement already satisfied: moviepy in /usr/local/lib/python3.12/dist-packages (1.0.3)\n","Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.4.2)\n","Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.12/dist-packages (from moviepy) (4.67.1)\n","Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.32.4)\n","Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.1.12)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.0.2)\n","Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.12/dist-packages (from moviepy) (2.37.0)\n","Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from moviepy) (0.6.0)\n","Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.12/dist-packages (from imageio<3.0,>=2.5->moviepy) (11.3.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2025.8.3)\n","Mounted at /content/drive\n","Scanning Google Drive for video files...\n","Files in your Google Drive:\n","MyDrive/\n","  📹 videoplayback.mp4\n","  BankChurn/\n","  Colab Notebooks/\n","  BANK-CHURN-PREDICTION/\n","    data/\n","  WhisperPython/\n","    📹 videoplayback.mp4\n","\n","Processing video: /content/drive/MyDrive/videoplayback.mp4\n","Processing local video: /content/drive/MyDrive/videoplayback.mp4\n","Loading Whisper model: base\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████| 139M/139M [00:16<00:00, 8.72MiB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Transcribing: videoplayback.mp4\n","\n","✅ Analysis Complete!\n","Video: videoplayback.mp4\n","Language detected: en\n","Transcript length: 8507 characters\n","Total segments: 187\n","\n","🔍 Found 0 keyword matches:\n","\n","💡 Found 74 potential topics:\n","  ⏰ 00:00 - Because I think right now, if I was to quit rapping and I say I want to go to th...\n","  ⏰ 00:15 - Why would you think you could make it to the NBA?...\n","  ⏰ 00:24 - Without a doubt you will see me on the UFC in the near future....\n","  ⏰ 01:06 - Breaks the world record for the fastest time to run a mile....\n","  ⏰ 01:14 - At the time, everyone believed that four minutes was the barrier....\n","Results saved to Google Drive:\n","- video_analysis_transcript.txt\n","- video_analysis_keywords.json\n","- video_analysis_summary.json\n","\n","🚀 QUICK SETUP INSTRUCTIONS:\n","\n","1. Upload your video to Google Drive\n","2. Run the drive.mount() cell to connect to Google Drive\n","3. Update the video_path variable with your actual video path\n","4. Customize keywords_to_search with your specific terms\n","5. Run the main processing function\n","6. Check the results and saved files in your Google Drive\n","\n","📝 Supported formats: MP4, AVI, MKV, MOV, WMV, FLV, WebM, M4V, MP3, WAV, M4A, FLAC, AAC\n","\n","⚡ Model options (speed vs accuracy):\n","- tiny: Fastest, least accurate\n","- base: Good balance (recommended)\n","- small: Better accuracy\n","- medium: High accuracy, slower\n","- large: Best accuracy, slowest\n","\n"]}]}]}